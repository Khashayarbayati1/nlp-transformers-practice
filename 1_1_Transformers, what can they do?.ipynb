{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78aa2384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9322eb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: I'm proud of myself.\n",
      "The predicted tone is 'POSITIVE' with a confidence score of 0.9999.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", device=device)\n",
    "\n",
    "text = \"I'm proud of myself.\"\n",
    "result = classifier(text)[0]\n",
    "\n",
    "print(\"Input Text:\", text)\n",
    "print(f\"The predicted tone is '{result['label']}' with a confidence score of {result['score']:.4f}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0deb855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: The prime minister announced a new climate policy to reduce carbon emissions.\n",
      "\n",
      "Top Predictions:\n",
      "environment     → 0.6812\n",
      "politics        → 0.2844\n",
      "technology      → 0.0193\n",
      "sports          → 0.0081\n",
      "entertainment   → 0.0071\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=device)\n",
    "\n",
    "text = \"The prime minister announced a new climate policy to reduce carbon emissions.\"\n",
    "candidate_labels = [\"politics\", \"environment\", \"sports\", \"entertainment\", \"technology\"]\n",
    "\n",
    "result = classifier(text, candidate_labels)\n",
    "    \n",
    "    \n",
    "print(\"Input Text:\", text)\n",
    "print(\"\\nTop Predictions:\")\n",
    "for label, score in zip(result[\"labels\"], result[\"scores\"]):\n",
    "    print(f\"{label:15} → {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b6c582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a world ruled by machines, a scientist discovered a hidden code that could make your life more difficult if you don't get enough sleep.\n",
      "/Getty Images 2 / Getty 3 AP 4 Reuters 5 EPA 6 / REUTERS 7/50 14 September 2018 Speaking in Malmo today he announced his support for an anti-fox hunting policy which would prevent the deployment of US military personnel to combat or intervene overseas, during another event at National Farmers Park on August 18th this year PA wire 8\"soDeliveryDate 17 Indian Prime Minister Narendra Modi greets schoolchildren after him said there was \"no\n",
      "In a world ruled by machines, a scientist discovered a hidden code that could unlock one of the most powerful weapons in human history.\n",
      " \"The program is called D-Gravity,\" said Dr. Andrew Hennig from Harvard Medical School who was not involved with the study or its findings at UMass Lowell University's Center for Computational Biology and Biotechnology but acknowledged it may be just what our ancestors did when they were children.\"Dressors Mihai Wu (University College London) explained: \"We humans might have been able to see through their bodies if we took\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"gpt2\", device=device)\n",
    "\n",
    "prompt = \"In a world ruled by machines, a scientist discovered a hidden code that could\"\n",
    "output = generator(prompt,\n",
    "                    max_new_tokens=100, \n",
    "                    num_return_sequences=2,\n",
    "                    top_k=50, # keep only the top k highest-probability ones\n",
    "                    top_p=0.95, # nucleus sampling: he smallest possible set of tokens whose cumulative probability ≥ p\n",
    "                    temperature=0.8, # Controls randomness\n",
    "                    repetition_penalty=1.2)\n",
    "\n",
    "for idx in range(len(output)):\n",
    "    print(output[idx]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73eadd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the capital of france is paris. (score: 0.4168)\n",
      "the capital of france is lille. (score: 0.0714)\n",
      "the capital of france is lyon. (score: 0.0634)\n",
      "the capital of france is marseille. (score: 0.0444)\n",
      "the capital of france is tours. (score: 0.0303)\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "result = unmasker(\"The capital of France is [MASK].\",\n",
    "                  top_k = 5)\n",
    "\n",
    "for prediction in result:\n",
    "    print(f\"{prediction['sequence']} (score: {prediction['score']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e77d0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER: Sarah (score: 0.9995)\n",
      "LOC: United Arab Emirates (score: 0.9994)\n",
      "ORG: Emirates Airlines (score: 0.9976)\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
    "results = ner(\"My friend Sarah flew to the United Arab Emirates with Emirates Airlines.\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"{result['entity_group']}: {result['word']} (score: {result['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c94894d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: When was the Eiffel Tower built?\n",
      "A: 1889 (score: 0.9755)\n"
     ]
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")\n",
    "\n",
    "question = \"When was the Eiffel Tower built?\"\n",
    "context = (\n",
    "    \"The Eiffel Tower is one of the most famous landmarks in the world. \"\n",
    "    \"It was constructed in Paris, France, in 1889 as the entrance arch to the 1889 World's Fair. \"\n",
    "    \"Standing 300 meters tall, it was the tallest man-made structure in the world for 41 years.\"\n",
    ")\n",
    "result = question_answerer(\n",
    "    question=question,\n",
    "    context=context,\n",
    ")\n",
    "print(f\"Q: {question}\")\n",
    "print(f\"A: {result['answer']} (score: {result['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d513599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norwegian Wood is a poignant coming-of-age novel by Haruki Murakami. The story is narrated by Toru Watanabe, a quiet and introspective college student in 1960s Tokyo. The novel follows Toru's emotional journey as he is pulled between the memories of his past and the possibilities of the present.\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "text = (\n",
    "    \"\"\"\n",
    "    Norwegian Wood is a poignant coming-of-age novel by Haruki Murakami that explores themes of love, loss, depression, and emotional maturation. The story is narrated by Toru Watanabe, a quiet and introspective college student in 1960s Tokyo, who is haunted by memories of his youth—especially his relationship with Naoko, the emotionally fragile girlfriend of his best friend Kizuki, who died by suicide. \n",
    "    As Toru and Naoko grow closer, her psychological instability deepens, and she moves to a secluded mental health retreat. Their relationship is marked by longing and emotional distance, burdened by past traumas. Meanwhile, Toru meets Midori, a vibrant and outspoken classmate who represents a stark contrast to Naoko. Midori is bold, alive, and emotionally open, offering Toru a potential path toward healing and connection.\n",
    "    The novel follows Toru's emotional journey as he is pulled between the memories of his past and the possibilities of the present. Through richly detailed introspection and deeply personal encounters, Murakami crafts a meditation on youth, death, desire, and the painful beauty of human connection.\n",
    "    In the end, Toru is left with a sense of ambiguity—neither fully healed nor broken—still searching for meaning in a world marked by impermanence. Norwegian Wood is not a story with tidy resolutions, but rather one that lingers with readers through its melancholic tone and emotional depth.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "summary = summarizer(text)\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2b1cc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khashayar/miniconda3/envs/nlp_may_25/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:177: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use cuda\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: She bought fresh bread from the bakery every morning.\n",
      "French Translation: Elle achetait du pain frais à la boulangerie tous les matins.\n",
      "English Reconstruction: She bought fresh bread from the bakery every morning.\n"
     ]
    }
   ],
   "source": [
    "en_fr_translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\", device=device)\n",
    "fr_en_translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\", device=device)\n",
    "\n",
    "english_text = \"She bought fresh bread from the bakery every morning.\"\n",
    "print(f\"Original Text: {english_text}\")\n",
    "\n",
    "fr_translation = en_fr_translator(english_text)[0]['translation_text']\n",
    "print(f\"French Translation: {fr_translation}\")\n",
    "\n",
    "en_reconstructed = fr_en_translator(fr_translation)[0]['translation_text']\n",
    "print(f\"English Reconstruction: {en_reconstructed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0643dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lynx, catamount: 0.4335\n",
      "cougar, puma, catamount, mountain lion, painter, panther, Felis concolor: 0.0348\n",
      "snow leopard, ounce, Panthera uncia: 0.0324\n",
      "Egyptian cat: 0.0239\n",
      "tiger cat: 0.0229\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    "image = Image.open(BytesIO(requests.get(url).content))\n",
    "\n",
    "image_classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
    "\n",
    "result = image_classifier(image)\n",
    "\n",
    "for label in result:\n",
    "    print(f\"{label['label']}: {label['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d69c187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/home/khashayar/miniconda3/envs/nlp_may_25/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}\n"
     ]
    }
   ],
   "source": [
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-large-v3\")\n",
    "\n",
    "url = \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\"\n",
    "\n",
    "result = transcriber(url)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36552a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_may_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
